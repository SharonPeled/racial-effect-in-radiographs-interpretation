{"cells":[{"cell_type":"code","source":["# pull\n","%cd \"/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images\"\n","!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gY_fjx-dmkVd","executionInfo":{"status":"ok","timestamp":1655401574907,"user_tz":-180,"elapsed":1464,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"539928b1-e9db-4ab6-e35a-8c898818b975"},"id":"gY_fjx-dmkVd","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images\n","Already up to date.\n"]}]},{"cell_type":"code","source":["# commit\n","!git config --global user.email \"ssharon95@gmail.com\"\n","!git config --global user.name \"SharonPeled\"\n","!git commit -a -m \"handling cuda out of memory error\""],"metadata":{"id":"ovlYXnGUmlNg"},"id":"ovlYXnGUmlNg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push\n","!git config --global user.email \"ssharon95@gmail.com\"\n","!git config --global user.name \"SharonPeled\"\n","%cd \"/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images\"\n","!git push"],"metadata":{"id":"yEllmVeumlVD"},"id":"yEllmVeumlVD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat \"/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline/utils.py\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDSoOO35mlXq","executionInfo":{"status":"ok","timestamp":1655401631146,"user_tz":-180,"elapsed":1608,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"071ae3bf-48fa-4894-a45f-bf52b472d796"},"id":"JDSoOO35mlXq","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["from dataclasses import dataclass\n","import numpy as np\n","import os\n","import torch\n","from torch import nn\n","from torchmetrics.functional import auc\n","import random\n","import datetime\n","\n","\n","@dataclass\n","class Configs:\n","    SEED = 123\n","    NUM_CLASSES = 5\n","    ANNOTATIONS_COLUMNS = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Pleural Effusion\"]\n","    UONES_COLUMNS = [\"Edema\", \"Pleural Effusion\", \"Atelectasis\"]\n","    UZEROS_COLUMNS = [\"Cardiomegaly\", \"Consolidation\"]\n","\n","\n","def set_seed():\n","    torch.manual_seed(Configs.SEED)\n","    random.seed(Configs.SEED)\n","    np.random.seed(Configs.SEED)\n","\n","\n","def to_gpu(x):\n","    return x.cuda() if torch.cuda.is_available() else x\n","\n","\n","def get_time_str():\n","    time_str = str(datetime.datetime.now())[:-10]\n","    trans = str.maketrans(\"-: \",\"__-\")\n","    return time_str.translate(trans)\n","\n","\n","def create_checkpoint(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs):\n","    valid_loss, valid_auc = calc_auc_score(model, valid_dataloader, criterion)\n","    results['valid_loss'].append(valid_loss.item())\n","    results['valid_auc'].append(valid_auc)\n","    metadata = {\n","        \"epoch\": epoch,\n","        \"iter\": i,\n","        \"trainLastLoss\": np.mean(results[\"train_loss\"][-100:]),\n","        \"validAUC\": results[\"valid_auc\"][-1]\n","    }\n","    time_str = get_time_str()\n","    metadata_suffix = '__'.join([f\"{k}-{round(v,4)}\" for k, v in metadata.items()])\n","    filename = f\"{time_str}__{TrainingConfigs.MODEL_VERSION}__{metadata_suffix}.dict\"\n","    filepath = os.path.join(TrainingConfigs.CHECKPOINT_DIR, filename)\n","    statedata = {**metadata, **{\"model\": model.state_dict(), \"results\": results}}\n","    torch.save(statedata, filepath)\n","    print(f\"{time_str}: Checkpoint Created.\")\n","\n","\n","def avg_auc(outputs, labels):\n","    softmax = nn.Softmax(dim=1)\n","    probas = softmax(outputs).T\n","    return np.mean([auc(y_proba, y_true, reorder=True) for y_proba, y_true in zip(probas, labels.T)])\n","\n","\n","def calc_auc_score(model, dataloader, criterion=None):\n","    all_labels = []\n","    all_outputs = []\n","    model.eval()\n","    with torch.no_grad():\n","      for i, (images, labels) in enumerate(dataloader):\n","          images = to_gpu(images)\n","          outputs = model(images).cpu()\n","          all_outputs.append(outputs)\n","          labels = labels.cpu()\n","          all_labels.append(labels)\n","    all_outputs, all_labels = torch.cat(all_outputs), torch.cat(all_labels)\n","    auc_value = avg_auc(all_outputs, all_labels)\n","    if auc_value > 1:\n","        print(all_outputs, all_labels)\n","        input()\n","    loss_value = None\n","    if criterion:\n","        loss_value = criterion(all_outputs, all_labels)\n","    model.train()\n","    return loss_value, auc_value\n","\n","\n","def get_previos_training_place(model, TrainingConfigs):\n","    if TrainingConfigs.TRAINED_MODEL_PATH:\n","        return load_statedict(model, TrainingConfigs.TRAINED_MODEL_PATH)\n","    _, _, files = next(os.walk(TrainingConfigs.CHECKPOINT_DIR))\n","    if not files:\n","        results = {\n","            \"train_loss\": [],\n","            \"valid_loss\": [],\n","            \"valid_auc\": []\n","        }\n","        return model, results, 0, -1\n","    model_filename = [filename for filename in files if filename.split(\"__\")[1] == TrainingConfigs.MODEL_VERSION][-1]\n","    return load_statedict(model, os.path.join(TrainingConfigs.CHECKPOINT_DIR, model_filename))\n","\n","\n","def load_statedict(model, path):\n","    statedata = torch.load(path)\n","    model.load_state_dict(statedata['model'])\n","    statedata['model'] = model\n","    return [statedata[k] for k in ['model', 'results', 'epoch', 'iter']]\n","\n","\n","\n"]}]},{"cell_type":"code","source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6-n5ac7OMl_","executionInfo":{"status":"ok","timestamp":1655399356112,"user_tz":-180,"elapsed":9842,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"b408f955-b46d-4edc-f606-537e79355e9d"},"id":"s6-n5ac7OMl_","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=3798e41af0dc7f42515bcae51bb88a317f75c50cfb1e2813236694854b8c89a0\n","  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Gen RAM Free: 12.0 GB  |     Proc size: 749.9 MB\n","GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total     15109MB\n"]}]},{"cell_type":"code","source":["import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","import torch \n","\n","torch.cuda.empty_cache()\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fKv8ekLSiKCu","executionInfo":{"status":"ok","timestamp":1655400467649,"user_tz":-180,"elapsed":698,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"172f9e98-7f28-4fde-aa20-a1a94dde6e43"},"id":"fKv8ekLSiKCu","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Gen RAM Free: 12.6 GB  |     Proc size: 344.0 MB\n","GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total     15109MB\n"]}]},{"cell_type":"code","source":["!pkill -9 -f ipykernel_launcher"],"metadata":{"id":"CHZCMgAqjlPp"},"id":"CHZCMgAqjlPp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os \n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"uqHCt1ZyfQuS","executionInfo":{"status":"ok","timestamp":1655399334657,"user_tz":-180,"elapsed":5,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"77b33dae-69eb-4706-ecf6-efe11cbdd422"},"id":"uqHCt1ZyfQuS","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["%cd \"/home/\"\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1bAxozbPPJ8","executionInfo":{"status":"ok","timestamp":1655396686352,"user_tz":-180,"elapsed":7,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"da9568bc-7d3f-4c66-d97c-75fc45007c6f"},"id":"T1bAxozbPPJ8","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/home\n"]}]},{"cell_type":"code","source":["!wget \"https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks%3Furl%3Dhttp%253A%252F%252Fdownload.cs.stanford.edu%252Fdeep%252FCheXpert-v1.0-small.zip%26h%3Dd560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5%26v%3D1%26xid%3D69567474fa%26uid%3D55365305%26pool%3Dcontact_facing%26subject%3DCheXpert-v1.0%253A%2BSubscription%2BConfirmed&data=05%7C01%7Csharonpe%40campus.technion.ac.il%7Cde77057e56b8487a125408da492d649b%7Cf1502c4cee2e411c9715c855f6753b84%7C1%7C0%7C637902757328007032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=jRoszYt%2F8%2B%2Fe5PlGojS4CCWb%2F2R1l9e32TX5weyYpX8%3D&reserved=0\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-u-wVd9WPUua","outputId":"64d1ee41-9ed5-4665-c593-d6a77e0629cd","executionInfo":{"status":"ok","timestamp":1655398894768,"user_tz":-180,"elapsed":2205364,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"id":"-u-wVd9WPUua","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["The name is too long, 595 chars total.\n","Trying to shorten...\n","New name is index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&.\n","--2022-06-16 16:24:49--  https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks%3Furl%3Dhttp%253A%252F%252Fdownload.cs.stanford.edu%252Fdeep%252FCheXpert-v1.0-small.zip%26h%3Dd560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5%26v%3D1%26xid%3D69567474fa%26uid%3D55365305%26pool%3Dcontact_facing%26subject%3DCheXpert-v1.0%253A%2BSubscription%2BConfirmed&data=05%7C01%7Csharonpe%40campus.technion.ac.il%7Cde77057e56b8487a125408da492d649b%7Cf1502c4cee2e411c9715c855f6753b84%7C1%7C0%7C637902757328007032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=jRoszYt%2F8%2B%2Fe5PlGojS4CCWb%2F2R1l9e32TX5weyYpX8%3D&reserved=0\n","Resolving eur01.safelinks.protection.outlook.com (eur01.safelinks.protection.outlook.com)... 104.47.2.28, 104.47.0.28, 2a01:111:f400:fe1f::28, ...\n","Connecting to eur01.safelinks.protection.outlook.com (eur01.safelinks.protection.outlook.com)|104.47.2.28|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://us13.mailchimp.com/mctx/clicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&pool=contact_facing&subject=CheXpert-v1.0%3A+Subscription+Confirmed [following]\n","The name is too long, 595 chars total.\n","Trying to shorten...\n","New name is index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&.\n","--2022-06-16 16:24:51--  https://us13.mailchimp.com/mctx/clicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&pool=contact_facing&subject=CheXpert-v1.0%3A+Subscription+Confirmed\n","Resolving us13.mailchimp.com (us13.mailchimp.com)... 104.89.119.59\n","Connecting to us13.mailchimp.com (us13.mailchimp.com)|104.89.119.59|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: http://download.cs.stanford.edu/deep/CheXpert-v1.0-small.zip [following]\n","The name is too long, 595 chars total.\n","Trying to shorten...\n","New name is index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&.\n","--2022-06-16 16:24:51--  http://download.cs.stanford.edu/deep/CheXpert-v1.0-small.zip\n","Resolving download.cs.stanford.edu (download.cs.stanford.edu)... 171.64.64.22\n","Connecting to download.cs.stanford.edu (download.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11557753157 (11G) [application/zip]\n","Saving to: â€˜index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&â€™\n","\n","index.html?url=http 100%[===================>]  10.76G  5.15MB/s    in 36m 43s \n","\n","2022-06-16 17:01:34 (5.00 MB/s) - â€˜index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&â€™ saved [11557753157/11557753157]\n","\n"]}]},{"cell_type":"code","source":["prev = 'index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&'\n","!mv \"index.html?url=https:%2F%2Fus13.mailchimp.com%2Fmctx%2Fclicks?url=http%3A%2F%2Fdownload.cs.stanford.edu%2Fdeep%2FCheXpert-v1.0-small.zip&h=d560d6d552da464fcc07b567091b41f6024e92218c1f46c47d0c2750d094e9a5&v=1&xid=69567474fa&uid=55365305&\" \"CheXpert-v1.0-small.zip\"\n"],"metadata":{"id":"_LQsHtK6dL56","executionInfo":{"status":"ok","timestamp":1655398894773,"user_tz":-180,"elapsed":37,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"id":"_LQsHtK6dL56","execution_count":7,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","from tqdm.notebook import tqdm\n","path_to_zip_file = r\"/home/CheXpert-v1.0-small.zip\"\n","directory_to_extract_to = r\"/home\"\n","with zipfile.ZipFile(path_to_zip_file) as zf:\n","  for member in tqdm(zf.infolist(), desc='Extracting '):\n","    try:\n","      zf.extract(member, directory_to_extract_to)\n","    except zipfile.error as e:\n","      pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["61d110d74b8c4068a6d95e4d2eea463e","1b129734267b42cabcc74ef0827a9a63","1b1c27fa1d2043fc8c9bdb8d4a6d8a19","412147c24b4b405d8f5537315d89ff9b","990a89e6e6f4418f934e1774d4159c39","597f87b2b039433c9d23bebba291c88a","e8ed4f29758e4613b5e04ff6688c904e","c3dca176f85e410ab5859a7f8616f291","496a20fbd2e1458395a00d65a243b169","0d6d5f879e364fe88ecaee406609a442","9f7132e4c0074f759300756a2d07af36"]},"id":"_BYDPzAydYYD","executionInfo":{"status":"ok","timestamp":1655399063945,"user_tz":-180,"elapsed":169201,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"3081c8f0-ab42-40d8-a45b-4a40e0e23070"},"id":"_BYDPzAydYYD","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Extracting :   0%|          | 0/476235 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61d110d74b8c4068a6d95e4d2eea463e"}},"metadata":{}}]},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"6EamiraQdppc","executionInfo":{"status":"ok","timestamp":1655399883839,"user_tz":-180,"elapsed":4,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"id":"6EamiraQdppc","execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":10,"id":"17224e4d","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:16.429934Z","start_time":"2022-06-14T11:34:16.394336Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"17224e4d","executionInfo":{"status":"ok","timestamp":1655399260115,"user_tz":-180,"elapsed":196184,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"c229f69b-414e-431c-cb2e-c6f0c0a2c6e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419 kB 37.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.9.1\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline\"\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline\")\n","# !pip install -r \"/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/requirements.txt\"\n","!pip install torchmetrics"]},{"cell_type":"code","execution_count":3,"id":"454b361c","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:18.717694Z","start_time":"2022-06-14T11:34:16.865637Z"},"id":"454b361c","executionInfo":{"status":"ok","timestamp":1655400863605,"user_tz":-180,"elapsed":428,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import time\n","from itertools import islice\n","from dataclasses import dataclass\n","\n","# pd.set_option('display.max_columns', 500)\n","# pd.set_option('display.max_rows', 500)\n","# import warnings\n","# warnings.filterwarnings('ignore')\n","# C:/Users/sshar/AppData/Roaming/jupyter/nbextensions/snippets /snippets.json (jupyter --data-dir)"]},{"cell_type":"code","execution_count":27,"id":"cac0214a","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:19.517473Z","start_time":"2022-06-14T11:34:19.266975Z"},"id":"cac0214a","executionInfo":{"status":"ok","timestamp":1655399970922,"user_tz":-180,"elapsed":431,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"outputs":[],"source":["from dataset import CheXpertDataset\n","import utils\n","from utils import to_gpu"]},{"cell_type":"code","execution_count":2,"id":"32197dbc","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:20.142776Z","start_time":"2022-06-14T11:34:20.066337Z"},"id":"32197dbc","colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"status":"error","timestamp":1655400856826,"user_tz":-180,"elapsed":1207,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"1f5f17c8-186e-4b0f-d621-0c3b23432fff"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f20ccf54781f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTrainingConfigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataclass' is not defined"]}],"source":["@dataclass\n","class TrainingConfigs:\n","    BATCH_SIZE = 2\n","    DATA_DIR = \"/home\"\n","    EPOCHS = 3\n","    LEARNING_RATE = 0.0001\n","    CHECKPOINT_TIME_INTERVAL = 3 # seconds\n","    CHECKPOINT_DIR = r\"model_checkpoints\"\n","    MODEL_VERSION = \"densenet121\"\n","    TRAINED_MODEL_PATH = None\n","    TRAIN_LOADER_SIZE = None\n","    VALID_LOADER_SIZE = None"]},{"cell_type":"code","execution_count":18,"id":"2789695b","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:20.847119Z","start_time":"2022-06-14T11:34:20.780315Z"},"id":"2789695b","executionInfo":{"status":"ok","timestamp":1655399393294,"user_tz":-180,"elapsed":548,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"outputs":[],"source":["utils.set_seed()"]},{"cell_type":"code","execution_count":19,"id":"cd6c2525","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:21.491154Z","start_time":"2022-06-14T11:34:21.416781Z"},"id":"cd6c2525","executionInfo":{"status":"ok","timestamp":1655399395438,"user_tz":-180,"elapsed":3,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((320,320)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","valid_transform = transforms.Compose([\n","    transforms.Resize((320,320)),\n","    transforms.ToTensor(), \n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":20,"id":"b601946d","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:24.666393Z","start_time":"2022-06-14T11:34:22.252182Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"b601946d","executionInfo":{"status":"ok","timestamp":1655399399243,"user_tz":-180,"elapsed":1807,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"406c41fb-e1c9-401e-cf67-20e368abc34c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["223414"]},"metadata":{},"execution_count":20}],"source":["# Create data loaders.\n","train_dataset = CheXpertDataset(mode='train', data_dir=TrainingConfigs.DATA_DIR, transform=train_transform)\n","train_dataloader = DataLoader(train_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=True)\n","TrainingConfigs.TRAIN_LOADER_SIZE = len(train_dataloader)\n","len(train_dataset)"]},{"cell_type":"code","execution_count":21,"id":"1ded129c","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:34:25.560246Z","start_time":"2022-06-14T11:34:25.457002Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"1ded129c","executionInfo":{"status":"ok","timestamp":1655399399244,"user_tz":-180,"elapsed":8,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"670baf91-22e3-479a-8846-91f23dd71774"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["234"]},"metadata":{},"execution_count":21}],"source":["valid_dataset = CheXpertDataset(mode='valid', data_dir=TrainingConfigs.DATA_DIR, transform=valid_transform)\n","valid_dataset.labels = valid_dataset.labels # hack for speed debugging\n","valid_dataloader = DataLoader(valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n","TrainingConfigs.VALID_LOADER_SIZE = len(valid_dataloader)\n","len(valid_dataset)"]},{"cell_type":"code","execution_count":22,"id":"20b3109b","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:42:09.805687Z","start_time":"2022-06-14T11:42:09.439714Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"20b3109b","executionInfo":{"status":"ok","timestamp":1655399401036,"user_tz":-180,"elapsed":1375,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"9af1fb51-e7bc-4f48-acd4-aafd4adbd09f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n"]}],"source":["torch.hub._validate_not_a_forked_repo = lambda a,b,c: True # workaround for torch.hub\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=False)\n","model.classifier = nn.Linear(in_features=1024, out_features=utils.Configs.NUM_CLASSES, bias=True) # updating model output dim"]},{"cell_type":"code","execution_count":23,"id":"71f82b75","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:42:11.129761Z","start_time":"2022-06-14T11:42:11.036404Z"},"id":"71f82b75","executionInfo":{"status":"ok","timestamp":1655399401036,"user_tz":-180,"elapsed":3,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=TrainingConfigs.LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":30,"id":"01a579d4","metadata":{"ExecuteTime":{"end_time":"2022-06-14T11:43:37.929352Z","start_time":"2022-06-14T11:43:16.055941Z"},"colab":{"base_uri":"https://localhost:8080/","height":556,"referenced_widgets":["7308b281aa6a4017bc027c0497be97f8","3de7db19949a4aeb98dfcd72a755ad4e","173d1ae447ef4e688758c76eeff0dcff","b8c33fdde5c8474e8a287875adba62bc","c8e86c9c67934ea99c08b8a84fbe26d2","f11d8f704c31464d856e006ac7b1a077","292de39627b14f2cae6c87a63dcae6f2","c0e8279297dd4203b745ef955f9f1867","cea1895162554a989d6db4f7aa5f3571","5870a6298fbb4cc5ba9fb2656f80c7ec","cf762e5a7ce149e79c777543027c8b26"]},"id":"01a579d4","executionInfo":{"status":"error","timestamp":1655400036544,"user_tz":-180,"elapsed":990,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}},"outputId":"a0b3285c-7ecc-42ef-b148-c052a7e4230e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/111707 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7308b281aa6a4017bc027c0497be97f8"}},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-91636c24828f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 14.76 GiB total capacity; 13.35 GiB already allocated; 5.75 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-91636c24828f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingConfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   print('Epoch [%d/%d],   Iter [%d/%d],   Train Loss: %.4f,   Valid Loss: %.4f,   Valid AUC: %.4f' \n\u001b[1;32m     36\u001b[0m           %(epoch+1, TrainingConfigs.EPOCHS,\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline/utils.py\u001b[0m in \u001b[0;36mcreate_checkpoint\u001b[0;34m(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingConfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline/utils.py\u001b[0m in \u001b[0;36mcalc_auc_score\u001b[0;34m(model, dataloader, criterion)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m           \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m           \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/debiasing-racial-effect-in-medical-images/CheXpert-baseline/utils.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.35 GiB already allocated; 5.75 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# TODO: try except in create_checkpoint to save model anyway\n","# TODO: move print to create_checkpoint\n","# TODO: update training to handle any batch size\n","# TODO: when cuda fails to reload kernel\n","model, results, last_epoch, last_iter = utils.get_previos_training_place(model, TrainingConfigs)\n","last_epoch, last_iter\n","model.train()\n","model = to_gpu(model)\n","start_time = time.time()\n","try:\n","  for epoch in range(last_epoch, TrainingConfigs.EPOCHS):\n","    train_dataloader_iter = islice(tqdm(enumerate(train_dataloader), total=len(train_dataloader)), \n","                                    last_iter+1, len(train_dataloader)) # fast foward dataloader\n","    for i, (images, labels) in train_dataloader_iter:\n","        images = to_gpu(images)\n","        labels = to_gpu(labels)        \n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        torch.cuda.empty_cache()\n","        results['train_loss'].append(loss.item())\n","        if time.time()-start_time > TrainingConfigs.CHECKPOINT_TIME_INTERVAL:\n","            utils.create_checkpoint(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs)\n","            start_time = time.time()\n","except Exception as e:\n","  utils.create_checkpoint(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs)\n","  print(e)"]},{"cell_type":"code","execution_count":29,"id":"b9895657","metadata":{"ExecuteTime":{"end_time":"2022-06-10T12:19:27.612516Z","start_time":"2022-06-10T12:19:26.945319Z"},"id":"b9895657","executionInfo":{"status":"ok","timestamp":1655400011801,"user_tz":-180,"elapsed":582,"user":{"displayName":"Sharon Peled","userId":"04092438056925526879"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"86ecf6f8","metadata":{"id":"86ecf6f8"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"training_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"61d110d74b8c4068a6d95e4d2eea463e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b129734267b42cabcc74ef0827a9a63","IPY_MODEL_1b1c27fa1d2043fc8c9bdb8d4a6d8a19","IPY_MODEL_412147c24b4b405d8f5537315d89ff9b"],"layout":"IPY_MODEL_990a89e6e6f4418f934e1774d4159c39"}},"1b129734267b42cabcc74ef0827a9a63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_597f87b2b039433c9d23bebba291c88a","placeholder":"â€‹","style":"IPY_MODEL_e8ed4f29758e4613b5e04ff6688c904e","value":"Extracting : 100%"}},"1b1c27fa1d2043fc8c9bdb8d4a6d8a19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3dca176f85e410ab5859a7f8616f291","max":476235,"min":0,"orientation":"horizontal","style":"IPY_MODEL_496a20fbd2e1458395a00d65a243b169","value":476235}},"412147c24b4b405d8f5537315d89ff9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d6d5f879e364fe88ecaee406609a442","placeholder":"â€‹","style":"IPY_MODEL_9f7132e4c0074f759300756a2d07af36","value":" 476235/476235 [02:43&lt;00:00, 3080.42it/s]"}},"990a89e6e6f4418f934e1774d4159c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"597f87b2b039433c9d23bebba291c88a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8ed4f29758e4613b5e04ff6688c904e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3dca176f85e410ab5859a7f8616f291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496a20fbd2e1458395a00d65a243b169":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d6d5f879e364fe88ecaee406609a442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f7132e4c0074f759300756a2d07af36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7308b281aa6a4017bc027c0497be97f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3de7db19949a4aeb98dfcd72a755ad4e","IPY_MODEL_173d1ae447ef4e688758c76eeff0dcff","IPY_MODEL_b8c33fdde5c8474e8a287875adba62bc"],"layout":"IPY_MODEL_c8e86c9c67934ea99c08b8a84fbe26d2"}},"3de7db19949a4aeb98dfcd72a755ad4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f11d8f704c31464d856e006ac7b1a077","placeholder":"â€‹","style":"IPY_MODEL_292de39627b14f2cae6c87a63dcae6f2","value":"  0%"}},"173d1ae447ef4e688758c76eeff0dcff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0e8279297dd4203b745ef955f9f1867","max":111707,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cea1895162554a989d6db4f7aa5f3571","value":0}},"b8c33fdde5c8474e8a287875adba62bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5870a6298fbb4cc5ba9fb2656f80c7ec","placeholder":"â€‹","style":"IPY_MODEL_cf762e5a7ce149e79c777543027c8b26","value":" 0/111707 [00:00&lt;?, ?it/s]"}},"c8e86c9c67934ea99c08b8a84fbe26d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11d8f704c31464d856e006ac7b1a077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"292de39627b14f2cae6c87a63dcae6f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0e8279297dd4203b745ef955f9f1867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cea1895162554a989d6db4f7aa5f3571":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5870a6298fbb4cc5ba9fb2656f80c7ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf762e5a7ce149e79c777543027c8b26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}