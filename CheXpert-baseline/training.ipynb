{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e444e587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T16:37:46.940284Z",
     "start_time": "2022-07-05T16:37:46.892391Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d55693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:38:18.987902Z",
     "start_time": "2022-07-09T16:38:18.934437Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17224e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:38:19.746210Z",
     "start_time": "2022-07-09T16:38:19.746210Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1448fcbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:38:26.049622Z",
     "start_time": "2022-07-09T16:38:24.664987Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from itertools import islice\n",
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "from torchvision.models import densenet161, DenseNet161_Weights, vit_b_16, ViT_B_16_Weights\n",
    "import os\n",
    "\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# C:/Users/sshar/AppData/Roaming/jupyter/nbextensions/snippets /snippets.json (jupyter --data-dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a229bcd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:38:23.726011Z",
     "start_time": "2022-07-09T16:38:20.230685Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import CheXpertDataset\n",
    "import utils\n",
    "from utils import vprint\n",
    "from utils import to_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb18e27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aa839a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:07.728898Z",
     "start_time": "2022-07-09T16:41:07.607973Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfigs:\n",
    "    DATA_DIR = os.path.join(\"..\", \"data\", \"CheXpert\", \"CheXpert-v1.0-small\")\n",
    "    CHECKPOINT_DIR = r\"checkpoints\"\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 0.0001\n",
    "    CHECKPOINT_TIME_INTERVAL = 5 # seconds\n",
    "    MODEL_VERSION = \"vit_b_16\"\n",
    "    TRAINED_MODEL_PATH = None\n",
    "    TRAIN_LOADER_SIZE = None\n",
    "    VALID_LOADER_SIZE = None\n",
    "    VALID_SIZE = 48 # for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05edd208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:08.978709Z",
     "start_time": "2022-07-09T16:41:08.890889Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55e4d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efee021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4fbe3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:10.291554Z",
     "start_time": "2022-07-09T16:41:10.206843Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "#     transforms.Resize((320,320)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#     # augmentation \n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.01)], p=0.1),\n",
    "    transforms.RandomApply([torchvision.transforms.GaussianBlur(kernel_size=(3,3) ,sigma=(0.25, 0.75))], p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.75, p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=1.25, p=0.1)\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "#     transforms.Resize((320,320)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76241d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:15.454474Z",
     "start_time": "2022-07-09T16:41:11.488764Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223414"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data loaders.\n",
    "train_dataset = CheXpertDataset(labels_filename='train.csv', data_dir=TrainingConfigs.DATA_DIR, transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=True)\n",
    "TrainingConfigs.TRAIN_LOADER_SIZE = len(train_dataloader)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7023c125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:16.646849Z",
     "start_time": "2022-07-09T16:41:16.534895Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = CheXpertDataset(labels_filename='valid.csv', data_dir=TrainingConfigs.DATA_DIR, transform=valid_transform)\n",
    "valid_dataset.labels = valid_dataset.labels[:TrainingConfigs.VALID_SIZE] # hack for speed debugging\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "TrainingConfigs.VALID_LOADER_SIZE = len(valid_dataloader)\n",
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbf1dd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:17.791228Z",
     "start_time": "2022-07-09T16:41:17.703228Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = densenet161(weights=DenseNet161_Weights.DEFAULT)\n",
    "# num_features = model.classifier.in_features\n",
    "# model.classifier = nn.Sequential(\n",
    "#     nn.Linear(num_features, num_features, bias=True),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.1),\n",
    "#     nn.Linear(in_features=num_features, out_features=utils.Configs.NUM_CLASSES, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a894d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:20.815063Z",
     "start_time": "2022-07-09T16:41:18.818839Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "num_features = model.heads.head.in_features\n",
    "model.heads.head = nn.Sequential(\n",
    "    nn.Linear(num_features, num_features, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(in_features=num_features, out_features=utils.Configs.NUM_CLASSES, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a9d20fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:41:22.341545Z",
     "start_time": "2022-07-09T16:41:22.177265Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=TrainingConfigs.LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, mode='min')\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean') # combines BCEntropy and sigmoid\n",
    "# final nn labels: torch.round(torch.sigmoid(pred))\n",
    "# simple solution to handle the multi label problem (probabilities don't have to sum to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b4a7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aea0f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T16:42:46.687072Z",
     "start_time": "2022-07-09T16:41:23.523171Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 19:41: Loaded model - epoch:0, iter:6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba78d2e924124fa088b7c3e0f979597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-09 19:41: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "2022-07-09 19:41: 2022_07_09-19_41: Checkpoint Created.\n",
      "2022-07-09 19:41: Epoch [1/10],   Iter [7/55853],   Train Loss: 0.3646,   Valid Loss: -1.0000,   Valid AUC: -1.0000\n",
      "\n",
      "2022-07-09 19:42: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "2022-07-09 19:42: 2022_07_09-19_42: Checkpoint Created.\n",
      "2022-07-09 19:42: Epoch [1/10],   Iter [8/55853],   Train Loss: 0.3681,   Valid Loss: -1.0000,   Valid AUC: -1.0000\n",
      "\n",
      "2022-07-09 19:42: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "2022-07-09 19:42: 2022_07_09-19_42: Checkpoint Created.\n",
      "2022-07-09 19:42: Epoch [1/10],   Iter [9/55853],   Train Loss: 0.3767,   Valid Loss: -1.0000,   Valid AUC: -1.0000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time \u001b[38;5;241m>\u001b[39m TrainingConfigs\u001b[38;5;241m.\u001b[39mCHECKPOINT_TIME_INTERVAL:\n\u001b[1;32m---> 18\u001b[0m         \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingConfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m         start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     20\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(np\u001b[38;5;241m.\u001b[39mmean(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader):]))\n",
      "File \u001b[1;32mC:\\Projects\\Msc\\ML_Healthcare\\debiasing-racial-effect-in-medical-images\\CheXpert-baseline\\utils.py:63\u001b[0m, in \u001b[0;36mcreate_checkpoint\u001b[1;34m(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_checkpoint\u001b[39m(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m         valid_loss, valid_auc \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m         results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(valid_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     65\u001b[0m         results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(valid_auc)\n",
      "File \u001b[1;32mC:\\Projects\\Msc\\ML_Healthcare\\debiasing-racial-effect-in-medical-images\\CheXpert-baseline\\utils.py:93\u001b[0m, in \u001b[0;36mcalc_scores\u001b[1;34m(scores, model, dataloader, criterion)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_scores\u001b[39m(scores, model, dataloader, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 93\u001b[0m     labels, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mget_metric_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     scores_val \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m scores:\n",
      "File \u001b[1;32mC:\\Projects\\Msc\\ML_Healthcare\\debiasing-racial-effect-in-medical-images\\CheXpert-baseline\\utils.py:109\u001b[0m, in \u001b[0;36mget_metric_tensors\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m    108\u001b[0m     images \u001b[38;5;241m=\u001b[39m to_gpu(images)\n\u001b[1;32m--> 109\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     all_outputs\u001b[38;5;241m.\u001b[39mappend(outputs)\n\u001b[0;32m    111\u001b[0m     all_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torchvision\\models\\vision_transformer.py:298\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    295\u001b[0m batch_class_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_token\u001b[38;5;241m.\u001b[39mexpand(n, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    296\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([batch_class_token, x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 298\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# Classifier \"token\" as used by standard language architectures\u001b[39;00m\n\u001b[0;32m    301\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torchvision\\models\\vision_transformer.py:157\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    155\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torchvision\\models\\vision_transformer.py:113\u001b[0m, in \u001b[0;36mEncoderBlock.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    111\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    115\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1113\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         why_not_fast_path \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad is enabled and at least one of query or the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1111\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/output projection weights or biases requires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m why_not_fast_path:\n\u001b[1;32m-> 1113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_native_multi_head_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m            \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m any_nested \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mis_nested \u001b[38;5;129;01mor\u001b[39;00m key\u001b[38;5;241m.\u001b[39mis_nested \u001b[38;5;129;01mor\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_nested\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_nested, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiheadAttention does not support NestedTensor outside of its fast path. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1128\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe fast path was not hit because \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhy_not_fast_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, results, last_epoch, last_iter = utils.get_previous_training_place(model, TrainingConfigs)\n",
    "model.train()\n",
    "model = to_gpu(model)\n",
    "start_time = time.time()\n",
    "for epoch in range(last_epoch, TrainingConfigs.EPOCHS):\n",
    "    train_dataloader_iter = islice(tqdm(enumerate(train_dataloader), total=len(train_dataloader)), \n",
    "                                   last_iter+1, len(train_dataloader)) # fast foward dataloader\n",
    "    for i, (images, labels) in train_dataloader_iter:\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        results['train_loss'].append(loss.item())\n",
    "        if time.time()-start_time > TrainingConfigs.CHECKPOINT_TIME_INTERVAL:\n",
    "            utils.create_checkpoint(model, epoch, i, valid_dataloader, criterion, results, TrainingConfigs)\n",
    "            start_time = time.time()\n",
    "    scheduler.step(np.mean(results[\"valid_loss\"][-len(train_dataloader):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6053c75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fee686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T15:44:00.750466Z",
     "start_time": "2022-07-09T15:44:00.171373Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f07fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T15:42:06.016768Z",
     "start_time": "2022-07-09T15:42:05.884190Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e70913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9895657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T12:19:27.612516Z",
     "start_time": "2022-06-10T12:19:26.945319Z"
    },
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecf6f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
