{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d55693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:16.508271Z",
     "start_time": "2022-06-14T05:55:16.412587Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17224e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:16.982845Z",
     "start_time": "2022-06-14T05:55:16.884654Z"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454b361c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:24.475493Z",
     "start_time": "2022-06-14T05:55:17.166721Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms, utils\n",
    "from torchmetrics.functional import auc\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# C:/Users/sshar/AppData/Roaming/jupyter/nbextensions/snippets /snippets.json (jupyter --data-dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac0214a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:24.788970Z",
     "start_time": "2022-06-14T05:55:24.636596Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import CheXpertDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32197dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:59:17.912655Z",
     "start_time": "2022-06-14T05:59:17.693197Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfigs:\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 3\n",
    "    LEARNING_RATE = 0.0001\n",
    "    CHECKPOINT_TIME_INTERVAL = 8 # seconds\n",
    "    CHECKPOINT_DIR = r\"model_checkpoints\"\n",
    "    MODEL_VERSION = \"densenet121\"\n",
    "    TRAINED_MODEL_PATH = \"2022_06_11-20_08__densenet121__epoch-0__iter-11__trainLastLoss-2.0778__validAUC-0.0019.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2789695b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:33.064240Z",
     "start_time": "2022-06-14T05:55:32.857162Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(Configs.SEED)\n",
    "random.seed(Configs.SEED)\n",
    "np.random.seed(Configs.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751695aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:33.971086Z",
     "start_time": "2022-06-14T05:55:33.821064Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_gpu(x):\n",
    "    return x.cuda() if torch.cuda.is_available() else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76cf4560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:41.450947Z",
     "start_time": "2022-06-14T05:55:41.289527Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_time_str():\n",
    "    time_str = str(datetime.datetime.now())[:-10]\n",
    "    trans = str.maketrans(\"-: \",\"__-\")\n",
    "    return time_str.translate(trans)\n",
    "\n",
    "def create_checkpoint(model, epoch, i, valid_dataloader, criterion, results):\n",
    "    valid_loss, valid_auc = calc_auc_score(model, valid_dataloader, criterion)\n",
    "    results['valid_loss'].append(loss.item())\n",
    "    results['valid_auc'].append(valid_auc)\n",
    "    metadata = {\n",
    "        \"epoch\": epoch,\n",
    "        \"iter\": i,\n",
    "        \"trainLastLoss\": np.mean(results[\"train_loss\"][-100:]),\n",
    "        \"validAUC\": results[\"valid_auc\"][-1]\n",
    "    }\n",
    "    time_str = get_time_str()\n",
    "    metadata_suffix = '__'.join([f\"{k}-{round(v,4)}\" for k, v in metadata.items()])\n",
    "    filename = f\"{time_str}__{TrainingConfigs.MODEL_VERSION}__{metadata_suffix}.dict\"\n",
    "    filepath = os.path.join(TrainingConfigs.CHECKPOINT_DIR, filename)\n",
    "    statedata = {**metadata, **{\"model\": model.state_dict(), \"results\": results}}\n",
    "    torch.save(statedata, filepath)\n",
    "    print(f\"{time_str}: Checkpoint Created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af9dc1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:43.335453Z",
     "start_time": "2022-06-14T05:55:43.183173Z"
    }
   },
   "outputs": [],
   "source": [
    "def avg_auc(outputs, labels):\n",
    "    probas = softmax(outputs).T\n",
    "    return np.mean([auc(y_proba, y_true, reorder=True) for y_proba, y_true in zip(probas, labels.T)])\n",
    "\n",
    "\n",
    "def calc_auc_score(model, dataloader, criterion=None):\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    model.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = to_gpu(images)\n",
    "        outputs = model(images).cpu()\n",
    "        all_outputs.append(outputs)\n",
    "        labels = labels.cpu()\n",
    "        all_labels.append(labels)\n",
    "    all_outputs, all_labels = torch.cat(all_outputs), torch.cat(all_labels)\n",
    "    auc_value = avg_auc(all_outputs, all_labels)\n",
    "    if auc_value > 1:\n",
    "        print(all_outputs, all_labels)\n",
    "        input()\n",
    "    loss_value = None\n",
    "    if criterion:\n",
    "        loss_value = criterion(all_outputs, all_labels)\n",
    "    model.train()\n",
    "    return loss_value, auc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6c2525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:44.576084Z",
     "start_time": "2022-06-14T05:55:44.425377Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b601946d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:50.240879Z",
     "start_time": "2022-06-14T05:55:45.051715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223414"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data loaders.\n",
    "train_dataset = CheXpertDataset(mode='train', transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ded129c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:57:44.292951Z",
     "start_time": "2022-06-14T05:57:44.003509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = CheXpertDataset(mode='valid', transform=valid_transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b3109b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:51.367782Z",
     "start_time": "2022-06-14T05:55:50.772092Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sshar/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "torch.hub._validate_not_a_forked_repo = lambda a,b,c: True # workaround for torch.hub\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=False)\n",
    "model.classifier = nn.Linear(in_features=1024, out_features=Configs.NUM_CLASSES, bias=True) # updating model output dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f82b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:55:51.683818Z",
     "start_time": "2022-06-14T05:55:51.529843Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=TrainingConfigs.LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6089f896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:59:29.673115Z",
     "start_time": "2022-06-14T05:59:29.517144Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_previos_training_place(model_filename):\n",
    "    if not model_filename:\n",
    "        return 0, -1\n",
    "    metadata = model_filename.split(\"__\")\n",
    "    last_epoch, last_iter = int(metadata[2][6:]), int(metadata[3][5:])\n",
    "    return last_epoch, last_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a836474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T05:59:31.134737Z",
     "start_time": "2022-06-14T05:59:30.971554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch, last_iter = get_previos_training_place(TrainingConfigs.TRAINED_MODEL_PATH)\n",
    "last_epoch, last_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01a579d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T06:00:24.918206Z",
     "start_time": "2022-06-14T05:59:45.468287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de6390f395045f89ec136630fe078b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_06_14-08_59: Checkpoint Created.\n",
      "Epoch [1/3],   Iter [13/55854],   Train Loss: 3.3292,   Valid Loss: 3.3292,   Valid AUC: 0.0021\n",
      "\n",
      "2022_06_14-09_00: Checkpoint Created.\n",
      "Epoch [1/3],   Iter [15/55854],   Train Loss: 2.1258,   Valid Loss: 1.8933,   Valid AUC: 0.0020\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14480\\369903048.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"train_loss\": [],\n",
    "    \"valid_loss\": [],\n",
    "    \"valid_auc\": []\n",
    "}\n",
    "checkpoint_time_int = 10 # seconds\n",
    "start_time = time.time()\n",
    "model.train()\n",
    "for epoch in range(last_epoch, TrainingConfigs.EPOCHS):\n",
    "    train_dataloader_iter = islice(tqdm(enumerate(train_dataloader), total=len(train_dataloader)), \n",
    "                                   last_iter+1, len(train_dataloader)) # fast foward dataloader\n",
    "    for i, (images, labels) in train_dataloader_iter:\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        results['train_loss'].append(loss.item())\n",
    "        if time.time()-start_time > TrainingConfigs.CHECKPOINT_TIME_INTERVAL:\n",
    "            create_checkpoint(model, epoch, i, valid_dataloader, criterion, results)\n",
    "            print('Epoch [%d/%d],   Iter [%d/%d],   Train Loss: %.4f,   Valid Loss: %.4f,   Valid AUC: %.4f' \n",
    "                   %(epoch+1, TrainingConfigs.EPOCHS,\n",
    "                     i, len(train_dataloader)-1, \n",
    "                     np.mean(results[\"train_loss\"][-100:]),\n",
    "                     results[\"valid_loss\"][-1],\n",
    "                     results[\"valid_auc\"][-1]),\n",
    "                 end=\"\\n\\n\")\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9895657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T12:19:27.612516Z",
     "start_time": "2022-06-10T12:19:26.945319Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecf6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
