{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153e22db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:45:03.118987Z",
     "start_time": "2022-07-23T17:45:03.101775Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf6530c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:45:03.387924Z",
     "start_time": "2022-07-23T17:45:03.376726Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd39014d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:46:54.710197Z",
     "start_time": "2022-07-23T17:46:52.365041Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from itertools import islice\n",
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "from torchvision.models import densenet161, DenseNet161_Weights, vit_b_16, ViT_B_16_Weights, densenet121, DenseNet121_Weights\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37509101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:46:55.783215Z",
     "start_time": "2022-07-23T17:46:54.773733Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from CheXpert.disease_prediction.dataset import CheXpertDiseaseDataset\n",
    "from shared_utils import vprint, to_gpu\n",
    "import shared_utils\n",
    "from CheXpert.disease_prediction.utils import Configs\n",
    "from CheXpert.race_prediction.utils import Configs as RaceConfigs\n",
    "from CheXpert.race_prediction.dataset import CheXpertRaceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbaf17f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa839a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:08.427039Z",
     "start_time": "2022-07-23T17:47:08.405689Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfigs(Configs):\n",
    "    DATA_DIR = os.path.join(\"..\", \"..\", \"data\", \"CheXpert\", \"CheXpert-v1.0-small\")\n",
    "    TRAIN_LABELS_ORIGINAL_FILENAME = \"train.csv\"\n",
    "    VALID_LABELS_ORIGINAL_FILENAME = \"valid.csv\"\n",
    "    TRAIN_LABELS_FILENAME = \"train_demo40_no_u_stratifiedV3.csv\"\n",
    "    VALID_LABELS_FILENAME = \"valid_demo40_no_u_stratifiedV3.csv\"\n",
    "    DEMO_FILENAME = \"CHEXPERT DEMO.csv\"\n",
    "    RACE_DICT = RaceConfigs.RACE_DICT\n",
    "    SAMPLE_NUM_STUDIES_PER_GROUP = 40\n",
    "    CHECKPOINT_DIR = r\"checkpoints\"\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 10\n",
    "    SAMPLE_WEIGHT_FACTOR = 0.6\n",
    "    LEARNING_RATE = 1e-4\n",
    "    LEARNING_RATE_REDUCE_PATIENCE = 3 # number of epochs with no improvement before reducing LR\n",
    "    LEARNING_RATE_REDUCING_FACTOR = 0.5\n",
    "    LEARNING_RATE_MIN_VAL = 1e-5\n",
    "    CHECKPOINT_TIME_INTERVAL = 60*60 # seconds\n",
    "    MODEL_VERSION = \"densenet121_disease_demo40_no_u_stratifiedV3\"\n",
    "    TRAINED_MODEL_PATH = None\n",
    "    TRAIN_LOADER_SIZE = None\n",
    "    VALID_LOADER_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d170e196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:09.340556Z",
     "start_time": "2022-07-23T17:47:09.284034Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shared_utils.set_seed(TrainingConfigs.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598aeba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:10.179658Z",
     "start_time": "2022-07-23T17:47:10.160575Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-21 21:01: Memory info: 8.5 GB free GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vprint(f\"Memory info: {torch.cuda.mem_get_info()[0]/10e8:.1f} GB free GPU.\", TrainingConfigs)\n",
    "else: \n",
    "    vprint(f\"No GPU Memory.\", TrainingConfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88527b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:10.179658Z",
     "start_time": "2022-07-23T17:47:10.160575Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27167/4265212713.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_c_train[Configs.ANNOTATIONS_COLUMNS] = df_c_train[Configs.ANNOTATIONS_COLUMNS].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# split train label file to train/valid files, where the valid file is consists of SAMPLE_NUM_PATIENTS_PER_GORUP patients\n",
    "# for each race, gender, and age groups\n",
    "# saves train/valid new created file to TRAIN_LABELS_FILENAME and VALID_LABELS_FILENAME, respectively\n",
    "\n",
    "if TrainingConfigs.SAMPLE_NUM_STUDIES_PER_GROUP is not None:\n",
    "    \n",
    "    # loading demo file\n",
    "    df_demo = CheXpertRaceDataset.generate_race_dummies(pd.read_csv(os.path.join(TrainingConfigs.DATA_DIR,\n",
    "                                                                             TrainingConfigs.DEMO_FILENAME)),\n",
    "                                                    'PRIMARY_RACE', TrainingConfigs.RACE_DICT)\n",
    "    \n",
    "    # loading train label file and joining demo attributes\n",
    "    df_train = pd.read_csv(os.path.join(TrainingConfigs.DATA_DIR, TrainingConfigs.TRAIN_LABELS_ORIGINAL_FILENAME))\n",
    "    df_train['patient_id'] = df_train.Path.apply(lambda p: p.split(\"/\")[2])\n",
    "    df_train = df_train.merge(df_demo, how='left', left_on='patient_id', right_on='PATIENT')\n",
    "    df_train['age'] = df_train.Age.apply(shared_utils.age_to_age_group)\n",
    "    df_train['gender'] = df_train.Sex\n",
    "    \n",
    "    # filter train to only patients with no uncertainty labels \n",
    "    is_patient_all_confident_labels = df_train.groupby(['patient_id'])[Configs.ANNOTATIONS_COLUMNS].apply(lambda s: (s==-1).sum(axis=1).sum(axis=0)==0)\n",
    "    confidence_patients = np.array(is_patient_all_confident_labels[is_patient_all_confident_labels].index)\n",
    "    df_c_train = df_train[df_train.patient_id.isin(confidence_patients)]\n",
    "    df_c_train[Configs.ANNOTATIONS_COLUMNS] = df_c_train[Configs.ANNOTATIONS_COLUMNS].fillna(0)\n",
    "    \n",
    "    # multi disease samples - prior in the training data\n",
    "    num_ones_per_study_proba = (df_c_train[Configs.ANNOTATIONS_COLUMNS]).sum(axis=1).value_counts()/len(df_c_train)\n",
    "    \n",
    "    # sample SAMPLE_NUM_PATIENTS_PER_GORUP per race, gender, age group\n",
    "    # stratified sampling according to ANNOTATIONS_COLUMNS\n",
    "    \n",
    "    # fractions of 0 and 1 in training\n",
    "    studies_per_protected_group_ones = df_c_train.groupby(['race', 'gender', 'age'])[Configs.ANNOTATIONS_COLUMNS].sum()\n",
    "    studies_per_protected_group_zeros = df_c_train.groupby(['race', 'gender', 'age'])[Configs.ANNOTATIONS_COLUMNS].agg(lambda s: sum(s==0))\n",
    "    studies_per_protected_group_ones = studies_per_protected_group_ones.merge(df_c_train.groupby(['race', 'gender', 'age']).size().to_frame(name=\"population_size\"), left_index=True, right_index=True)\n",
    "    studies_per_protected_group_zeros = studies_per_protected_group_zeros.merge(df_c_train.groupby(['race', 'gender', 'age']).size().to_frame(name=\"population_size\"), left_index=True, right_index=True)\n",
    "    \n",
    "    # from each race, age, gender and label in one of the label columns - sample the same fraction as in training.\n",
    "    df_list = []\n",
    "    chosen = set()\n",
    "    for attrs1, df_group1 in df_c_train.groupby(['race', 'gender', 'age']):\n",
    "        for col in Configs.ANNOTATIONS_COLUMNS:\n",
    "            for attrs2, df_group2 in df_group1.groupby(col, sort=True):\n",
    "                if attrs2==0:\n",
    "                    frac = studies_per_protected_group_zeros.loc[attrs1][col] / studies_per_protected_group_zeros.loc[attrs1]['population_size']\n",
    "                    n =  int(np.floor(TrainingConfigs.SAMPLE_NUM_STUDIES_PER_GROUP * frac))\n",
    "                else: \n",
    "                    frac = studies_per_protected_group_ones.loc[attrs1][col] / studies_per_protected_group_ones.loc[attrs1]['population_size']\n",
    "                    n =  int(np.ceil(TrainingConfigs.SAMPLE_NUM_STUDIES_PER_GROUP * frac))\n",
    "                chosen_filter = df_group2.index.isin(chosen)\n",
    "                df_group2 = df_group2[~chosen_filter]\n",
    "                n = max(0, n-sum(chosen_filter))\n",
    "                weights = num_ones_per_study_proba[(df_group2[TrainingConfigs.ANNOTATIONS_COLUMNS]==1).sum(axis=1)].values\n",
    "                df_list.append(df_group2.sample(n, weights=weights, replace=False, random_state=Configs.SEED))\n",
    "                chosen.update(set(df_list[-1].index))\n",
    "        sampled_studies = pd.concat(df_list)\n",
    "        sampled_studies.groupby(['race', 'gender', 'age']).size()\n",
    "    \n",
    "    # filter valid patients from training\n",
    "    df_valid_patients = sampled_studies.patient_id.unique()\n",
    "    \n",
    "    # saving files\n",
    "    df_train_group_split = df_train[~df_train.patient_id.isin(df_valid_patients)]\n",
    "    df_valid_group_split = sampled_studies\n",
    "    df_train_group_split.to_csv(os.path.join(TrainingConfigs.DATA_DIR, TrainingConfigs.TRAIN_LABELS_FILENAME), index=False)\n",
    "    df_valid_group_split.to_csv(os.path.join(TrainingConfigs.DATA_DIR, TrainingConfigs.VALID_LABELS_FILENAME), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415dc30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7134bfe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4fbe3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:16.134053Z",
     "start_time": "2022-07-23T17:47:16.124829Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    # augmentation\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.01)], p=0.1),\n",
    "    transforms.RandomApply([torchvision.transforms.GaussianBlur(kernel_size=(3,3) ,sigma=(0.25, 0.75))], p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.75, p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=1.25, p=0.1),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76241d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:21.119228Z",
     "start_time": "2022-07-23T17:47:18.126042Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220026"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data loaders.\n",
    "train_dataset = CheXpertDiseaseDataset(data_dir=TrainingConfigs.DATA_DIR, \n",
    "                                       labels_filename=TrainingConfigs.TRAIN_LABELS_FILENAME,\n",
    "                                       transform=train_transform,\n",
    "                                       sample_weight_factor=TrainingConfigs.SAMPLE_WEIGHT_FACTOR)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "TrainingConfigs.TRAIN_LOADER_SIZE = len(train_dataloader)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "915d8d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:25.830792Z",
     "start_time": "2022-07-23T17:47:25.776837Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = CheXpertDiseaseDataset(data_dir=TrainingConfigs.DATA_DIR, \n",
    "                                       labels_filename=TrainingConfigs.VALID_LABELS_FILENAME,\n",
    "                                       transform=valid_transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "TrainingConfigs.VALID_LOADER_SIZE = len(valid_dataloader)\n",
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e64269a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:25.830792Z",
     "start_time": "2022-07-23T17:47:25.776837Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race      gender  age  \n",
       "Asian     Female  20-40    48\n",
       "                  40-70    52\n",
       "                  70-90    54\n",
       "          Male    20-40    44\n",
       "                  40-70    51\n",
       "                  70-90    52\n",
       "Black     Female  20-40    45\n",
       "                  40-70    47\n",
       "                  70-90    50\n",
       "          Male    20-40    53\n",
       "                  40-70    49\n",
       "                  70-90    49\n",
       "Hispanic  Female  20-40    48\n",
       "                  40-70    54\n",
       "                  70-90    54\n",
       "          Male    20-40    48\n",
       "                  40-70    52\n",
       "                  70-90    52\n",
       "White     Female  20-40    49\n",
       "                  40-70    45\n",
       "                  70-90    54\n",
       "          Male    20-40    49\n",
       "                  40-70    47\n",
       "                  70-90    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.df_labels.groupby(['race', 'gender', 'age']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7023c125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:25.830792Z",
     "start_time": "2022-07-23T17:47:25.776837Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_valid_dataset = CheXpertDiseaseDataset(data_dir=TrainingConfigs.DATA_DIR, \n",
    "                                           labels_filename=TrainingConfigs.VALID_LABELS_ORIGINAL_FILENAME,\n",
    "                                           transform=valid_transform)\n",
    "org_valid_dataloader = DataLoader(org_valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "len(org_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbf1dd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:28.393276Z",
     "start_time": "2022-07-23T17:47:27.914035Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, num_features, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(in_features=num_features, out_features=TrainingConfigs.NUM_CLASSES, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db0d5f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:29.725904Z",
     "start_time": "2022-07-23T17:47:29.713539Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=TrainingConfigs.LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=TrainingConfigs.LEARNING_RATE_REDUCING_FACTOR,\n",
    "                                                       patience=TrainingConfigs.LEARNING_RATE_REDUCE_PATIENCE, mode='min',\n",
    "                                                       min_lr=TrainingConfigs.LEARNING_RATE_MIN_VAL)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean') # combines BCEntropy and sigmoid\n",
    "# final nn labels: torch.round(torch.sigmoid(pred))\n",
    "# simple solution to handle the multi label problem (probabilities don't have to sum to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa493b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:29.725904Z",
     "start_time": "2022-07-23T17:47:29.713539Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(reduction='none') # combines BCEntropy and sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38ef12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aea0f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:58.140001Z",
     "start_time": "2022-07-23T17:47:32.370832Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-21 21:02: \n",
      "2022-08-21 21:02: ----------------------------------------------------------------------------------------------------\n",
      "2022-08-21 21:02: ----------------------------------------------------------------------------------------------------\n",
      "2022-08-21 21:02: \n",
      "2022-08-21 21:02: Start Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea50dc9b4d134b0fb76e026a06d62ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13752 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-21 21:02: 2022_08_21-21_02: Checkpoint Created For densenet121_disease_demo40_no_u_stratifiedV3.\n",
      "2022-08-21 21:02: Epoch [0/10],   Iter [33/13751],   Train Loss: -0.4843,   Valid Loss: 0.7389,   Valid AUC: 0.6498\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(train_loss_list)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loss_list))\n\u001b[1;32m     34\u001b[0m train_loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 35\u001b[0m \u001b[43mshared_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingConfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_on_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_on_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mby_study\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchallenge_ann_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morg_valid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morg_valid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     39\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/MLH/debiasing-racial-effect-in-medical-images/shared_utils.py:71\u001b[0m, in \u001b[0;36mcreate_checkpoint\u001b[0;34m(model, optimizer, scheduler, criterion, epoch, i, valid_dataloader, results, Configs, score_dict, apply_on_outputs, by_study, challenge_ann_only, org_valid_dataloader)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_checkpoint\u001b[39m(model, optimizer, scheduler, criterion, epoch, i, valid_dataloader, results, Configs,\n\u001b[1;32m     69\u001b[0m                       score_dict, apply_on_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x, by_study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, challenge_ann_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, org_valid_dataloader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m         score_vals_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mapply_on_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_study\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchallenge_ann_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morg_valid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morg_valid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m score_name, score_value \u001b[38;5;129;01min\u001b[39;00m score_vals_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     74\u001b[0m             results[score_dict[score_name]]\u001b[38;5;241m.\u001b[39mappend(score_value)\n",
      "File \u001b[0;32m~/MLH/debiasing-racial-effect-in-medical-images/shared_utils.py:109\u001b[0m, in \u001b[0;36mcalc_scores\u001b[0;34m(scores, model, dataloader, Configs, criterion, apply_on_outputs, by_study, challenge_ann_only, org_valid_dataloader)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_scores\u001b[39m(scores, model, dataloader, Configs, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, apply_on_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x,\n\u001b[1;32m    108\u001b[0m                 by_study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, challenge_ann_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, org_valid_dataloader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 109\u001b[0m     labels, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mget_metric_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_on_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mby_study\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchallenge_ann_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     score_vals_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m scores:\n",
      "File \u001b[0;32m~/MLH/debiasing-racial-effect-in-medical-images/shared_utils.py:134\u001b[0m, in \u001b[0;36mget_metric_tensors\u001b[0;34m(model, dataloader, Configs, apply_on_outputs, by_study, challenge_ann_only)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m    133\u001b[0m     images \u001b[38;5;241m=\u001b[39m to_gpu(images)\n\u001b[0;32m--> 134\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     all_outputs\u001b[38;5;241m.\u001b[39mappend(outputs)\n\u001b[1;32m    136\u001b[0m     all_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torchvision/models/densenet.py:214\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 214\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    216\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torchvision/models/densenet.py:123\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    121\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 123\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torchvision/models/densenet.py:91\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[0;32m---> 91\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottleneck_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     93\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(new_features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_obj = shared_utils.get_previous_training_place(model, optimizer, scheduler, criterion, TrainingConfigs)\n",
    "model, optimizer, scheduler, criterion, results, last_epoch, last_iter = checkpoint_obj\n",
    "score_dict = {\n",
    "    \"auc\": \"valid_auc\",\n",
    "    \"original_valid_auc\": \"org_valid_auc\",\n",
    "    \"loss\": \"valid_loss\"\n",
    "}\n",
    "model.train()\n",
    "model = to_gpu(model)\n",
    "start_time = time.time()\n",
    "shared_utils.start_training_msg(TrainingConfigs)\n",
    "train_loss_list = []\n",
    "apply_on_outputs = lambda x: torch.sigmoid(x)\n",
    "for epoch in range(last_epoch, TrainingConfigs.EPOCHS):\n",
    "    train_dataloader_iter = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    if last_iter > -1:\n",
    "        # fast foward dataloader\n",
    "        train_dataloader_iter = islice(train_dataloader_iter, last_iter+1, len(train_dataloader))\n",
    "        last_iter = -1\n",
    "    for i, (images, labels, weights) in train_dataloader_iter:\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)\n",
    "        weights = to_gpu(weights)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        weights = weights[:, None]\n",
    "        loss = (loss * (weights/weights.sum())).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "        if time.time()-start_time > TrainingConfigs.CHECKPOINT_TIME_INTERVAL:\n",
    "            results['train_loss'].append(sum(train_loss_list)/len(train_loss_list))\n",
    "            train_loss_list = []\n",
    "            shared_utils.create_checkpoint(model, optimizer, scheduler, criterion, epoch, i, valid_dataloader,\n",
    "                                           results, TrainingConfigs, score_dict, apply_on_outputs=apply_on_outputs,\n",
    "                                           by_study=None, challenge_ann_only=None, org_valid_dataloader=org_valid_dataloader)\n",
    "            model.train()\n",
    "            start_time = time.time()\n",
    "    shared_utils.create_checkpoint(model, optimizer, scheduler, criterion, epoch, len(train_dataloader), valid_dataloader,\n",
    "                                   results, TrainingConfigs, score_dict, apply_on_outputs= apply_on_outputs, \n",
    "                                   by_study=None, challenge_ann_only=None, org_valid_dataloader=org_valid_dataloader)\n",
    "    scheduler.step(results[\"valid_loss\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
