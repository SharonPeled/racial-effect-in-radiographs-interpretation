{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153e22db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d55693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:45:03.118987Z",
     "start_time": "2022-07-23T17:45:03.101775Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf6530c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:45:03.387924Z",
     "start_time": "2022-07-23T17:45:03.376726Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd39014d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:46:54.710197Z",
     "start_time": "2022-07-23T17:46:52.365041Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from itertools import islice\n",
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "from torchvision.models import densenet161, DenseNet161_Weights, vit_b_16, ViT_B_16_Weights, densenet121, DenseNet121_Weights\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37509101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:46:55.783215Z",
     "start_time": "2022-07-23T17:46:54.773733Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from CheXpert.disease_prediction.dataset import CheXpertDiseaseDataset\n",
    "from shared_utils import vprint, to_gpu\n",
    "import shared_utils\n",
    "from CheXpert.disease_prediction.utils import Configs\n",
    "from CheXpert.race_prediction.utils import Configs as RaceConfigs\n",
    "from CheXpert.race_prediction.dataset import CheXpertRaceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbaf17f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa839a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:08.427039Z",
     "start_time": "2022-07-23T17:47:08.405689Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfigs(Configs):\n",
    "    DATA_DIR = os.path.join(\"..\", \"..\", \"data\", \"CheXpert\", \"CheXpert-v1.0-small\")\n",
    "    TRAIN_LABELS_ORIGINAL_FILENAME = \"train.csv\"\n",
    "    TRAIN_LABELS_FILENAME = \"train_demo30.csv\"\n",
    "    VALID_LABELS_FILENAME = \"valid_demo30.csv\"\n",
    "    DEMO_FILENAME = \"CHEXPERT DEMO.csv\"\n",
    "    RACE_DICT = RaceConfigs.RACE_DICT\n",
    "    SAMPLE_NUM_PATIENTS_PER_GORUP = 30\n",
    "    CHECKPOINT_DIR = r\"checkpoints\"\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-4\n",
    "    LEARNING_RATE_REDUCE_PATIENCE = 3 # number of epochs with no improvement before reducing LR\n",
    "    LEARNING_RATE_REDUCING_FACTOR = 0.5\n",
    "    LEARNING_RATE_MIN_VAL = 1e-5\n",
    "    CHECKPOINT_TIME_INTERVAL = 30*60 # seconds\n",
    "    MODEL_VERSION = \"densenet121_disease_aug_race30\"\n",
    "    TRAINED_MODEL_PATH = None\n",
    "    TRAIN_LOADER_SIZE = None\n",
    "    VALID_LOADER_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d170e196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:09.340556Z",
     "start_time": "2022-07-23T17:47:09.284034Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shared_utils.set_seed(TrainingConfigs.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598aeba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:10.179658Z",
     "start_time": "2022-07-23T17:47:10.160575Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-28 11:28: Memory info: 8.5 GB free GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vprint(f\"Memory info: {torch.cuda.mem_get_info()[0]/10e8:.1f} GB free GPU.\", TrainingConfigs)\n",
    "else: \n",
    "    vprint(f\"No GPU Memory.\", TrainingConfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb65e3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:10.179658Z",
     "start_time": "2022-07-23T17:47:10.160575Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split train label file to train/valid files, where the valid file is consists of SAMPLE_NUM_PATIENTS_PER_GORUP patients\n",
    "# for each race, gender, and age groups\n",
    "# saves train/valid new created file to TRAIN_LABELS_FILENAME and VALID_LABELS_FILENAME, respectively\n",
    "if TrainingConfigs.SAMPLE_NUM_PATIENTS_PER_GORUP is not None:\n",
    "    # loading demo file\n",
    "    df_demo = CheXpertRaceDataset.generate_race_dummies(pd.read_csv(os.path.join(TrainingConfigs.DATA_DIR,\n",
    "                                                                             TrainingConfigs.DEMO_FILENAME)),\n",
    "                                                    'PRIMARY_RACE', TrainingConfigs.RACE_DICT)\n",
    "    # loading train label file and joining demo attributes\n",
    "    df_train = pd.read_csv(os.path.join(TrainingConfigs.DATA_DIR, TrainingConfigs.TRAIN_LABELS_ORIGINAL_FILENAME))\n",
    "    df_train['patient_id'] = df_train.Path.apply(lambda p: p.split(\"/\")[2])\n",
    "    df_train = df_train.merge(df_demo, how='left', left_on='patient_id', right_on='PATIENT')\n",
    "    df_train['age'] = df_train.Age.apply(shared_utils.age_to_age_group)\n",
    "    df_train['gender'] = df_train.Sex\n",
    "    # sample SAMPLE_NUM_PATIENTS_PER_GORUP per race, gender, age group\n",
    "    df_train_patients = df_train[['patient_id', 'race', 'gender', 'age']].drop_duplicates()\n",
    "    train_patients_sample = df_train_patients.groupby(['race', 'gender', 'age']).sample(n=TrainingConfigs.SAMPLE_NUM_PATIENTS_PER_GORUP, \n",
    "                                                                                        random_state=TrainingConfigs.SEED,\n",
    "                                                                                        replace=False).patient_id\n",
    "    # saving files\n",
    "    df_train_group_split = df_train[~df_train.patient_id.isin(train_patients_sample)]\n",
    "    df_valid_group_split = df_train[df_train.patient_id.isin(train_patients_sample)]\n",
    "    df_train_group_split.to_csv(os.path.join(TrainingConfigs.DATA_DIR, TrainingConfigs.TRAIN_LABELS_FILENAME), index=False)\n",
    "    df_valid_group_split.to_csv(os.path.join(TrainingConfigs.DATA_DIR, TrainingConfigs.VALID_LABELS_FILENAME), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415dc30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7134bfe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4fbe3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:16.134053Z",
     "start_time": "2022-07-23T17:47:16.124829Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    # augmentation\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.01)], p=0.1),\n",
    "    transforms.RandomApply([torchvision.transforms.GaussianBlur(kernel_size=(3,3) ,sigma=(0.25, 0.75))], p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.75, p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=1.25, p=0.1),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76241d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:21.119228Z",
     "start_time": "2022-07-23T17:47:18.126042Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220807"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data loaders.\n",
    "train_dataset = CheXpertDiseaseDataset(data_dir=TrainingConfigs.DATA_DIR, \n",
    "                                       labels_filename=TrainingConfigs.TRAIN_LABELS_FILENAME,\n",
    "                                       transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "TrainingConfigs.TRAIN_LOADER_SIZE = len(train_dataloader)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7023c125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:25.830792Z",
     "start_time": "2022-07-23T17:47:25.776837Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2607"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = CheXpertDiseaseDataset(data_dir=TrainingConfigs.DATA_DIR, \n",
    "                                       labels_filename=TrainingConfigs.VALID_LABELS_FILENAME,\n",
    "                                       transform=valid_transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=True)\n",
    "TrainingConfigs.VALID_LOADER_SIZE = len(valid_dataloader)\n",
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf1dd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:28.393276Z",
     "start_time": "2022-07-23T17:47:27.914035Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, num_features, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(in_features=num_features, out_features=TrainingConfigs.NUM_CLASSES, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9d20fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:29.725904Z",
     "start_time": "2022-07-23T17:47:29.713539Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=TrainingConfigs.LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=TrainingConfigs.LEARNING_RATE_REDUCING_FACTOR,\n",
    "                                                       patience=TrainingConfigs.LEARNING_RATE_REDUCE_PATIENCE, mode='min',\n",
    "                                                       min_lr=TrainingConfigs.LEARNING_RATE_MIN_VAL)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean') # combines BCEntropy and sigmoid\n",
    "# final nn labels: torch.round(torch.sigmoid(pred))\n",
    "# simple solution to handle the multi label problem (probabilities don't have to sum to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38ef12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aea0f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T17:47:58.140001Z",
     "start_time": "2022-07-23T17:47:32.370832Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-28 11:28: \n",
      "2022-07-28 11:28: ----------------------------------------------------------------------------------------------------\n",
      "2022-07-28 11:28: ----------------------------------------------------------------------------------------------------\n",
      "2022-07-28 11:28: \n",
      "2022-07-28 11:28: Start Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153bc31166f044edb5533b540e0de249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/MLH/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_obj = shared_utils.get_previous_training_place(model, optimizer, scheduler, criterion, TrainingConfigs)\n",
    "model, optimizer, scheduler, criterion, results, last_epoch, last_iter = checkpoint_obj\n",
    "score_dict = {\n",
    "    \"auc\": \"valid_auc\",\n",
    "    \"loss\": \"valid_loss\"\n",
    "}\n",
    "model.train()\n",
    "model = to_gpu(model)\n",
    "start_time = time.time()\n",
    "shared_utils.start_training_msg(TrainingConfigs)\n",
    "train_loss_list = []\n",
    "apply_on_outputs = lambda x: torch.sigmoid(x)\n",
    "for epoch in range(last_epoch, TrainingConfigs.EPOCHS):\n",
    "    train_dataloader_iter = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    if last_iter > -1:\n",
    "        # fast foward dataloader\n",
    "        train_dataloader_iter = islice(train_dataloader_iter, last_iter+1, len(train_dataloader))\n",
    "        last_iter = -1\n",
    "    for i, (images, labels) in train_dataloader_iter:\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "        if time.time()-start_time > TrainingConfigs.CHECKPOINT_TIME_INTERVAL:\n",
    "            results['train_loss'].append(sum(train_loss_list)/len(train_loss_list))\n",
    "            train_loss_list = []\n",
    "            shared_utils.create_checkpoint(model, optimizer, scheduler, criterion, epoch, i, valid_dataloader,\n",
    "                                           results, TrainingConfigs, score_dict, apply_on_outputs=apply_on_outputs,\n",
    "                                           by_study=None, challenge_ann_only=None)\n",
    "            assert model.training\n",
    "            start_time = time.time()\n",
    "    shared_utils.create_checkpoint(model, optimizer, scheduler, criterion, epoch, len(train_dataloader), valid_dataloader,\n",
    "                                   results, TrainingConfigs, score_dict, apply_on_outputs= apply_on_outputs, \n",
    "                                   by_study=None, challenge_ann_only=None)\n",
    "    scheduler.step(results[\"valid_loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac5ff4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56242ce0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f6331",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
