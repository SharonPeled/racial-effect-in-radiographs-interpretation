{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a0b4be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d55693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:25:28.853025Z",
     "start_time": "2022-07-19T17:25:28.845325Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf6530c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:25:28.867985Z",
     "start_time": "2022-07-19T17:25:28.855018Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd39014d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:05.410046Z",
     "start_time": "2022-07-19T17:28:02.114380Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from itertools import islice\n",
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "from torchvision.models import densenet161, DenseNet161_Weights, vit_b_16, ViT_B_16_Weights, densenet121, DenseNet121_Weights\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37509101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:06.540200Z",
     "start_time": "2022-07-19T17:28:05.428254Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from CheXpert.race_prediction.dataset import CheXpertRaceDataset\n",
    "from CheXpert.shared_utils import vprint, to_gpu\n",
    "from CheXpert import shared_utils\n",
    "from CheXpert.race_prediction.utils import Configs, Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c29794",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa839a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:12.944814Z",
     "start_time": "2022-07-19T17:28:12.936832Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfigs(Configs):\n",
    "    DATA_DIR = os.path.join(\"..\", \"..\", \"data\", \"CheXpert\", \"CheXpert-v1.0-small\")\n",
    "    DEMO_FILENAME = \"CHEXPERT DEMO.csv\"\n",
    "    TRAIN_LABELS_FILENAME = \"train.csv\"\n",
    "    VALID_LABELS_FILENAME = \"valid.csv\"\n",
    "    CHECKPOINT_DIR = r\"checkpoints\"\n",
    "    DISEASE_PRETRAINED_MODEL_PATH = os.path.join(\"..\", \"disease_prediction\", \"trained_models\",\n",
    "                                                 \"2022_07_12-18_47__densenet121_aug__epoch-5__iter-12659__batch_size-16__trainLastLoss-0.3754__validAUC-0.8899.dict\")\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-4\n",
    "    LEARNING_RATE_REDUCE_PATIENCE = 3 # number of epochs with no improvement before reducing LR\n",
    "    LEARNING_RATE_REDUCING_FACTOR = 0.5\n",
    "    LEARNING_RATE_MIN_VAL = 1e-5\n",
    "    CHECKPOINT_TIME_INTERVAL = 60*60 # seconds\n",
    "    MODEL_VERSION = \"densenet121_race_classifier_freezed\"\n",
    "    FREEZING_POINT = \"classifier\"\n",
    "    MODE = Mode.Shallow\n",
    "    TRAINED_MODEL_PATH = None\n",
    "    TRAIN_LOADER_SIZE = None\n",
    "    VALID_LOADER_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d170e196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:13.809517Z",
     "start_time": "2022-07-19T17:28:13.791140Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shared_utils.set_seed(TrainingConfigs.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05edd208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:14.204966Z",
     "start_time": "2022-07-19T17:28:14.195001Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-19 20:28: No GPU Memory.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vprint(f\"Memory info: {torch.cuda.mem_get_info()[0]/10e8:.1f} GB free GPU.\", TrainingConfigs)\n",
    "else: \n",
    "    vprint(f\"No GPU Memory.\", TrainingConfigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d0efd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6324bc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4fbe3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:16.305859Z",
     "start_time": "2022-07-19T17:28:16.287849Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    # augmentation\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.01)], p=0.1),\n",
    "    transforms.RandomApply([torchvision.transforms.GaussianBlur(kernel_size=(3,3) ,sigma=(0.25, 0.75))], p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=0.75, p=0.1),\n",
    "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=1.25, p=0.1),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((320,320)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76241d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:21.226976Z",
     "start_time": "2022-07-19T17:28:16.918359Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data loaders.\n",
    "train_dataset = CheXpertRaceDataset(data_dir=TrainingConfigs.DATA_DIR, demo_filename=TrainingConfigs.DEMO_FILENAME,\n",
    "                                       labels_filename=TrainingConfigs.TRAIN_LABELS_FILENAME,\n",
    "                                       transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "TrainingConfigs.TRAIN_LOADER_SIZE = len(train_dataloader)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7023c125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:21.422622Z",
     "start_time": "2022-07-19T17:28:21.259542Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = CheXpertRaceDataset(data_dir=TrainingConfigs.DATA_DIR, demo_filename=TrainingConfigs.DEMO_FILENAME,\n",
    "                                       labels_filename=TrainingConfigs.VALID_LABELS_FILENAME,\n",
    "                                       transform=valid_transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=TrainingConfigs.BATCH_SIZE, shuffle=False)\n",
    "TrainingConfigs.VALID_LOADER_SIZE = len(valid_dataloader)\n",
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21740d23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:21.781721Z",
     "start_time": "2022-07-19T17:28:21.440527Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, num_features, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(in_features=num_features, out_features=TrainingConfigs.NUM_DISEASE_CLASSES, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed35726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:28:21.811713Z",
     "start_time": "2022-07-19T17:28:21.799185Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if TrainingConfigs.MODE == Mode.PartlyFreezed:\n",
    "    model = shared_utils.load_model(model, TrainingConfigs.DISEASE_PRETRAINED_MODEL_PATH)\n",
    "if TrainingConfigs.MODE == Mode.Full or TrainingConfigs.MODE == Mode.PartlyFreezed:\n",
    "    model.classifier[-1] = nn.Linear(in_features=num_features, out_features=TrainingConfigs.NUM_CLASSES, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b4eaf5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:37:38.707174Z",
     "start_time": "2022-07-19T17:37:38.461223Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if TrainingConfigs.MODE == Mode.Shallow:\n",
    "    num_features = 256\n",
    "    model = nn.Sequential(densenet121().features[:5],\n",
    "                          nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.ReLU(),\n",
    "                          nn.AdaptiveAvgPool2d((1, 1)),   \n",
    "                          nn.Flatten(start_dim=1),\n",
    "                          nn.Linear(in_features=num_features, out_features=num_features, bias=True),\n",
    "                          nn.Dropout(p=0.1),\n",
    "                          nn.Linear(in_features=num_features, out_features=TrainingConfigs.NUM_CLASSES, bias=True)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c3ed0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:37:39.084682Z",
     "start_time": "2022-07-19T17:37:39.066730Z"
    },
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (6): Dropout(p=0.1, inplace=False)\n",
       "  (7): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbf1dd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:37:39.876772Z",
     "start_time": "2022-07-19T17:37:39.864773Z"
    },
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# summary(model, input_size=[16, 3, 320, 320],\n",
    "#         col_names=(\"input_size\", \"output_size\", \"num_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "781264ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:37:40.271131Z",
     "start_time": "2022-07-19T17:37:40.259170Z"
    }
   },
   "outputs": [],
   "source": [
    "if TrainingConfigs.MODE == Mode.PartlyFreezed:\n",
    "    shared_utils.requires_grad_update_by_layer(model, TrainingConfigs, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "139e18c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:37:40.635462Z",
     "start_time": "2022-07-19T17:37:40.619452Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, model.parameters()), lr=TrainingConfigs.LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=TrainingConfigs.LEARNING_RATE_REDUCING_FACTOR,\n",
    "                                                       patience=TrainingConfigs.LEARNING_RATE_REDUCE_PATIENCE, mode='min',\n",
    "                                                       min_lr=TrainingConfigs.LEARNING_RATE_MIN_VAL)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "# requires softmax to retrieve probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceea286",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aea0f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-19T17:37:50.719464Z",
     "start_time": "2022-07-19T17:37:41.286798Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-19 20:37: \n",
      "2022-07-19 20:37: ----------------------------------------------------------------------------------------------------\n",
      "2022-07-19 20:37: ----------------------------------------------------------------------------------------------------\n",
      "2022-07-19 20:37: \n",
      "2022-07-19 20:37: Start Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114d5747b5d94a8984c6a62e1bce4581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m labels \u001b[38;5;241m=\u001b[39m to_gpu(labels)\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torchvision\\models\\densenet.py:123\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[1;34m(self, init_features)\u001b[0m\n\u001b[0;32m    121\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 123\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torchvision\\models\\densenet.py:91\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[1;32m---> 91\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottleneck_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     93\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(new_features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\MLH\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_obj = shared_utils.get_previous_training_place(model, optimizer, scheduler, criterion, TrainingConfigs)\n",
    "model, optimizer, scheduler, criterion, results, last_epoch, last_iter = checkpoint_obj\n",
    "score_dict = {\n",
    "    \"auc\": \"valid_auc\",\n",
    "    \"loss\": \"valid_loss\"\n",
    "}\n",
    "model.train()\n",
    "model = to_gpu(model)\n",
    "start_time = time.time()\n",
    "shared_utils.start_training_msg(TrainingConfigs)\n",
    "train_loss_list = []\n",
    "apply_on_outputs = lambda x: torch.softmax(x, dim=1)\n",
    "for epoch in range(last_epoch, TrainingConfigs.EPOCHS):\n",
    "    train_dataloader_iter = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    if last_iter > -1:\n",
    "        # fast foward dataloader\n",
    "        train_dataloader_iter = islice(train_dataloader_iter, last_iter+1, len(train_dataloader))\n",
    "        last_iter = -1\n",
    "    for i, (images, labels) in train_dataloader_iter:\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "        if time.time()-start_time > TrainingConfigs.CHECKPOINT_TIME_INTERVAL:\n",
    "            results['train_loss'].append(sum(train_loss_list)/len(train_loss_list))\n",
    "            train_loss_list = []\n",
    "            shared_utils.create_checkpoint(model, optimizer, scheduler, criterion, epoch, i, valid_dataloader,\n",
    "                                           results, TrainingConfigs, score_dict, \n",
    "                                           apply_on_outputs=apply_on_outputs,\n",
    "                                           by_study=None, challenge_ann_only=None)\n",
    "            assert model.training\n",
    "            start_time = time.time()\n",
    "    shared_utils.create_checkpoint(model, optimizer, scheduler, criterion, epoch, len(train_dataloader), valid_dataloader, \n",
    "                                   results, TrainingConfigs, score_dict, apply_on_outputs=apply_on_outputs,\n",
    "                                   by_study=None, challenge_ann_only=None)\n",
    "    scheduler.step(results[\"valid_loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d994444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T10:13:06.885172Z",
     "start_time": "2022-07-16T10:13:06.885172Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed4330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a366ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
